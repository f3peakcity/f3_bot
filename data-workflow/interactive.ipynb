{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(sheet_id: str, sheet_name: str = \"__RAW\") -> pd.DataFrame:\n",
    "    \"\"\"Get raw data from the spreadsheet and load to pandas for processing.\n",
    "    Manually specify the column names based on knowledge of the backblast format.\"\"\"\n",
    "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "    column_names = [\"date\", \"q\", \"ao\", \"n_pax\", \"pax\", \"pax_id\", \"n_fngs\", \"fng_id\", \"pax_no_slack\", \"n_visiting_pax\", \"submitter\", \"submitter_id\", \"id\", \"store_date\"]\n",
    "    df = pd.read_csv(url, names=column_names, parse_dates=[\"date\", \"store_date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_ao_data(sheet_id, sheet_name: str = \"__REFERENCE_AO_INFO\") -> pd.DataFrame:\n",
    "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "    column_names = [\"ao\", \"ao_normalized_name\", \"ao_type\", \"ao_region\", \"ao_day_of_week_int\", \"ao_lat\", \"ao_lon\"]\n",
    "    df = pd.read_csv(url, names=column_names, header=0)\n",
    "    df[\"ao_day_of_week_int\"] = df[\"ao_day_of_week_int\"].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_ao_info(df: pd.DataFrame, reference_ao_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add AO Info, and break ties when there is incorrect date information in a record.\n",
    "\n",
    "    If any downstream processing uses the normalized AO name, then the reference ao data must be\n",
    "    upated to ensure that all channel names are included in the list of normalied ao names.\n",
    "    \"\"\"\n",
    "    new = df.copy()\n",
    "    new[\"ao\"] = new[\"ao\"].fillna(\"1stf\")\n",
    "    new = new.merge(reference_ao_df, on=\"ao\", how=\"left\")\n",
    "    new[\"ao_normalized_name\"] = new[\"ao_normalized_name\"].fillna(new[\"ao\"])\n",
    "    new[\"raw_ao\"] = new[\"ao\"]\n",
    "    new[\"ao\"] = new[\"ao_normalized_name\"]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_of_week(df: pd.DataFrame, date_column: str = \"date\") -> pd.DataFrame:\n",
    "    \"\"\"Add a convenience column with the day of the week.\"\"\"\n",
    "\n",
    "    # In Looker Studio's WEEKDAY function, the value of Sunday is 0, therefore the value of Saturday is 6.\n",
    "    new = df.copy()\n",
    "    # In pandas dayofweek function, the value of Sunday is 6, and the value of Monday is 0\n",
    "    # We want to match the Looker Studio behavior, so we add 1 to the pandas dayofweek function\n",
    "    new[\"day_of_week_int\"] = new[f\"{date_column}\"].dt.dayofweek\n",
    "    new[\"day_of_week_int\"] = (new[\"day_of_week_int\"] + 1) % 7\n",
    "\n",
    "    date_diff = new[\"day_of_week_int\"] - new[\"ao_day_of_week_int\"]  # 0 if the day of week is correct\n",
    "    date_diff = date_diff.fillna(0)\n",
    "\n",
    "    # Correct the date in favor of the ao_day_of_week\n",
    "    new[\"date_raw\"] = new[f\"{date_column}\"]\n",
    "    new[f\"{date_column}\"] = new[f\"{date_column}\"] - pd.to_timedelta(date_diff, unit=\"d\")\n",
    "\n",
    "    new[\"day_of_week\"] = new[f\"{date_column}\"].dt.day_name()\n",
    "\n",
    "    # new.loc[\n",
    "    #     new[\"ao_day_of_week_int\"].notnull() & (new[\"day_of_week_int\"] != new[\"ao_day_of_week_int\"]),\n",
    "    #     \"day_of_week_int\"\n",
    "    # ] = new.loc[\n",
    "    #     new[\"ao_day_of_week_int\"].notnull() & (new[\"day_of_week_int\"] != new[\"ao_day_of_week_int\"]),\n",
    "    #     \"ao_day_of_week_int\"\n",
    "    # ].astype(\"int\")\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pax_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Slack ID is persistent, but names can change. Update the names in the dataframe\n",
    "    based on the last-used name of the PAX in the dataset.\"\"\"\n",
    "    # use most recent name for each pax\n",
    "    pax = df[[\"pax\", \"pax_id\"]].drop_duplicates(subset=[\"pax_id\"], keep=\"last\")\n",
    "    updated = df.merge(pax, on=\"pax_id\", how=\"left\", suffixes=(\"_then_name\", \"\"))\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_message_for_ao_q_day(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Deduplicate backblast messages by date, q, and ao. If multiple\n",
    "    messages were submitted for a single date/q/ao, keep the last one.\"\"\"\n",
    "    deduped = df[[\"date\", \"q\", \"ao\", \"id\"]].drop_duplicates(subset=[\"date\", \"q\", \"ao\"], keep=\"last\")\n",
    "    new = df.merge(deduped[\"id\"], on=[\"id\"], how=\"right\")\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_ao_type(df: pd.DataFrame, ao_type: str = \"1stf\") -> pd.DataFrame:\n",
    "    \"\"\"Filter the dataframe to only include AOs of the specified type.\"\"\"\n",
    "    new = df.loc[df[\"ao_type\"] == ao_type]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_as_list(df: pd.DataFrame, do_ao_rollup: bool = False) -> List[List[str]]:\n",
    "    \"\"\"Convert to a list of values to submit back to google sheets.\"\"\"\n",
    "    new = df.fillna(\"_\")\n",
    "    # reorder and drop columns (drop the old name, 'pax_then_name')\n",
    "    # new = new.drop(columns=[\"pax_then_name\"])\n",
    "    new = new[[\"date\", \"q\", \"ao\", \"n_pax\", \"pax\", \"day_of_week\", \"day_of_week_int\", \"pax_id\", \"n_fngs\", \"fng_id\", \"pax_no_slack\", \"n_visiting_pax\", \"ao_lat\", \"ao_lon\", \"submitter\", \"submitter_id\", \"id\", \"store_date\"]]\n",
    "    new[\"date\"] = new[\"date\"].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "    new[\"store_date\"] = new[\"store_date\"].apply(lambda x: x.strftime(\"%Y-%m-%dT%H:%M:%S.%f\"))\n",
    "    if do_ao_rollup:\n",
    "        # rollup by AO\n",
    "        ao_level = new.drop(columns=[\"pax\", \"pax_id\", \"fng_id\"])\n",
    "        ao_level = ao_level.drop_duplicates(subset=[\"date\", \"q\", \"ao\"], keep=\"last\")\n",
    "        values = ao_level.values.tolist()\n",
    "        ao_level_column_names = [\"Date\", \"Q\", \"AO\", \"PAX (count)\", \"Day of Week\", \"Day of Week - Int\", \"FNGs (count)\", \"PAX Not in Slack\", \"Visitng PAX (count)\", \"ao_lat\", \"ao_lon\", \"Submitter\", \"Submitter ID\", \"Backblast ID\", \"Backblast Timestamp\"]\n",
    "        values = [\n",
    "            ao_level_column_names,\n",
    "            *values\n",
    "        ]\n",
    "    else:\n",
    "        values = new.values.tolist()\n",
    "        pax_level_column_names = [\"Date\", \"Q\", \"AO\", \"PAX (count)\", \"PAX Name\", \"Day of Week\", \"Day of Week - Int\", \"PAX Slack ID\", \"FNGs (count)\", \"FNG ID\", \"PAX Not in Slack\", \"Visitng PAX (count)\", \"ao_lat\", \"ao_lon\", \"Submitter\", \"Submitter ID\", \"Backblast ID\", \"Backblast Timestamp\"]\n",
    "        values = [\n",
    "            pax_level_column_names,\n",
    "            *values\n",
    "        ]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_values(sheet_id: str, sheet_suffix: str, values: List[List[str]]) -> None:\n",
    "    \"\"\"Save the processed values back to google sheets.\"\"\"\n",
    "    done = False\n",
    "    try_count = 0\n",
    "\n",
    "\n",
    "    spreadsheet_request_body = {\n",
    "        \"values\": values\n",
    "    }\n",
    "    service = discovery.build('sheets', 'v4', cache_discovery=False)\n",
    "\n",
    "    while not done and try_count < 3:\n",
    "        try_count += 1\n",
    "        try:\n",
    "            result = service.spreadsheets().values().update(\n",
    "                spreadsheetId=sheet_id,\n",
    "                range=f\"__PROCESSED_{sheet_suffix}\",\n",
    "                body=spreadsheet_request_body,\n",
    "                valueInputOption=\"RAW\"\n",
    "            ).execute()\n",
    "            logger.info(f\"{result.get('updatedCells')} cells updated.\")\n",
    "            done = True\n",
    "        except (ConnectionError, HttpError) as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "            service = discovery.build('sheets', 'v4', cache_discovery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_pipeline(sheet_id: str):\n",
    "    # add day of week\n",
    "    # update pax names to use the most recent one in all records\n",
    "    # Remove duplicate records -- last one wins for each AO\n",
    "    df = get_raw_data(sheet_id=sheet_id)\n",
    "    reference_ao_df = get_reference_ao_data(sheet_id=sheet_id)\n",
    "    df = infer_ao_info(df, reference_ao_df)\n",
    "    df = add_day_of_week(df)\n",
    "    df = update_pax_names(df)\n",
    "    df = get_last_message_for_ao_q_day(df)\n",
    "    df = filter_by_ao_type(df, ao_type=\"1stf\")\n",
    "    pax_level_values = get_df_as_list(df, do_ao_rollup=False)\n",
    "    ao_level_values = get_df_as_list(df, do_ao_rollup=True)\n",
    "    save_processed_values(sheet_id=sheet_id, sheet_suffix=\"PAX\", values=pax_level_values)\n",
    "    save_processed_values(sheet_id=sheet_id, sheet_suffix=\"AO\", values=ao_level_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = os.environ.get(\"SPREADSHEET_ID\", \"1c1vvx07AXdnu6NSa4is4a0oyUiu8q3cgOecFbTNWlAY\")\n",
    "spreadsheet_id = sheet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_pipeline(sheet_id=sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_raw_data(sheet_id=sheet_id)\n",
    "reference_ao_df = get_reference_ao_data(sheet_id=sheet_id)\n",
    "df = infer_ao_info(df, reference_ao_df)\n",
    "df = add_day_of_week(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = update_pax_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[names[\"id\"] == \"21f0f620223542f492383e612cc9713f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[names[\"pax_id\"] == \"UDLCW1X36\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_raw_data(sheet_id=sheet_id)\n",
    "reference_ao_df = get_reference_ao_data(sheet_id=sheet_id)\n",
    "df = infer_ao_info(df, reference_ao_df)\n",
    "df = add_day_of_week(df)\n",
    "df = update_pax_names(df)\n",
    "df = get_last_message_for_ao_q_day(df)\n",
    "df = filter_by_ao_type(df, ao_type=\"1stf\")\n",
    "pax_level_values = get_df_as_list(df, do_ao_rollup=False)\n",
    "ao_level_values = get_df_as_list(df, do_ao_rollup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_raw_data(sheet_id=sheet_id)\n",
    "reference_ao_df = get_reference_ao_data(sheet_id=sheet_id)\n",
    "ao_info = infer_ao_info(df, reference_ao_df)\n",
    "# df = add_day_of_week(df)\n",
    "# df = update_pax_names(df)\n",
    "# df = get_last_message_for_ao_q_day(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_info = infer_ao_info(df, reference_ao_df)\n",
    "ao_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_info[ao_info[\"id\"] == \"4f4f95bb0aee4bad8dce95b54e1ab880\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = add_day_of_week(ao_info)\n",
    "dow[dow[\"id\"] == \"4f4f95bb0aee4bad8dce95b54e1ab880\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = update_pax_names(dow)\n",
    "names[names[\"id\"] == \"4f4f95bb0aee4bad8dce95b54e1ab880\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message = get_last_message_for_ao_q_day(names)\n",
    "last_message[last_message[\"id\"] == \"4f4f95bb0aee4bad8dce95b54e1ab880\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_by_ao_type(last_message, ao_type=\"1stf\")\n",
    "filtered[filtered[\"id\"] == \"4f4f95bb0aee4bad8dce95b54e1ab880\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_level_values = get_df_as_list(filtered, do_ao_rollup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in ao_level_values if \"4f4f95bb0aee4bad8dce95b54e1ab880\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f3_bot-8rVvG8VB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
